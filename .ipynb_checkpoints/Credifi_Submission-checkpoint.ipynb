{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credifi Credit Risk Analysis\n",
    "\n",
    "**Submission Format Requirements:**\n",
    "- All code and results are presented in this Jupyter Notebook.\n",
    "- Library imports, version listing, and reproducibility are ensured.\n",
    "- Well-commented code for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports and Version Listing\n",
    "import sys\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "print(f'Python version: {platform.python_version()}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'scikit-learn version: {sklearn.__version__}')\n",
    "print(f'XGBoost version: {xgboost.__version__}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Load the credit data and apply necessary preprocessing steps as per the project pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading, Cleaning, and Preprocessing\n",
    "from ml.data_processor import CreditDataProcessor\n",
    "\n",
    "# Initialize processor\n",
    "processor = CreditDataProcessor()\n",
    "\n",
    "# Load raw data\n",
    "data = processor.load_data('data/credit_data.csv')\n",
    "print(f'Dataset shape: {data.shape}')\n",
    "display(data.head())\n",
    "\n",
    "# Clean data\n",
    "clean_data = processor.clean_data(data)\n",
    "print('After cleaning:')\n",
    "display(clean_data.describe())\n",
    "\n",
    "# Encode categorical features\n",
    "encoded_data = processor.encode_categorical_features(clean_data)\n",
    "print('After encoding categorical features:')\n",
    "display(encoded_data.head())\n",
    "\n",
    "# Scale numerical features\n",
    "scaled_data = processor.scale_features(encoded_data)\n",
    "print('After scaling numerical features:')\n",
    "display(scaled_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "Train the XGBoost model, evaluate its performance, and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "from ml.model import CreditRiskModel\n",
    "\n",
    "# Initialize model\n",
    "risk_model = CreditRiskModel()\n",
    "\n",
    "# Train the model (set optimize_hyperparameters=True if you want grid search)\n",
    "results = risk_model.train_model(clean_data, optimize_hyperparameters=False)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Train Score:\", results['train_score'])\n",
    "print(\"Test Score:\", results['test_score'])\n",
    "print(\"Accuracy:\", results['accuracy'])\n",
    "print(\"AUC Score:\", results['auc_score'])\n",
    "print(\"Cross-Validation Mean:\", results['cv_mean'])\n",
    "print(\"Cross-Validation Std:\", results['cv_std'])\n",
    "\n",
    "# Classification report\n",
    "import pandas as pd\n",
    "cr = pd.DataFrame(results['classification_report']).transpose()\n",
    "display(cr)\n",
    "\n",
    "# Confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = results['confusion_matrix']\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "fi = results['feature_importance']\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(fi.values()), y=list(fi.keys()))\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis and Profit Optimization\n",
    "Analyze risk, assign interest rates, and determine profit optimization using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk Analysis and Profit Optimization\n",
    "from ml.risk_calculator import RiskCalculator\n",
    "\n",
    "# Prepare features for prediction\n",
    "X = risk_model.data_processor.prepare_features(clean_data, fit=False)\n",
    "y = clean_data[risk_model.target_column]\n",
    "\n",
    "# Get model probabilities\n",
    "y_pred = risk_model.model.predict(X)\n",
    "y_pred_proba = risk_model.model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Initialize risk calculator\n",
    "risk_calc = RiskCalculator()\n",
    "\n",
    "# Generate risk report\n",
    "risk_report = risk_calc.generate_risk_report(clean_data, y_pred, y_pred_proba)\n",
    "\n",
    "# Display key risk metrics\n",
    "print('Portfolio Metrics:')\n",
    "for k, v in risk_report['portfolio_metrics'].items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "print('\\nProfit Analysis:')\n",
    "for k, v in risk_report['profit_analysis'].items():\n",
    "    if k.endswith('_data'): continue  # Skip large DataFrames\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "print('\\nRisk Tier Distribution:')\n",
    "print(risk_report['tier_distribution'])\n",
    "\n",
    "# Show break-even analysis (optional)\n",
    "break_even = risk_calc.calculate_break_even_analysis(clean_data, pd.Series(y_pred_proba))\n",
    "display(break_even['break_even_analysis'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Explainability\n",
    "Visualize and interpret model predictions using SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Explainability\n",
    "import shap\n",
    "\n",
    "# Pick a sample application (first row)\n",
    "sample_app = clean_data.iloc[0].to_dict()\n",
    "\n",
    "# Generate SHAP explanation\n",
    "explanation = risk_model.explain_prediction(sample_app)\n",
    "\n",
    "# SHAP summary plot for the whole dataset\n",
    "explainer = shap.TreeExplainer(risk_model.model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Summary plot (feature importance across all samples)\n",
    "shap.summary_plot(shap_values, X, feature_names=X.columns)\n",
    "\n",
    "# Force plot for a single prediction (requires Jupyter, not just VSCode)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X.iloc[0, :], feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk and ROI Visualizations\n",
    "Visualize break-even analysis, risk tiers, and portfolio risk/return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize break-even analysis\n",
    "break_even_df = break_even['break_even_analysis']\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(break_even_df['acceptance_rate'], break_even_df['net_profit'], marker='o')\n",
    "plt.title('Net Profit vs. Acceptance Rate')\n",
    "plt.xlabel('Acceptance Rate')\n",
    "plt.ylabel('Net Profit')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Visualize risk tier distribution\n",
    "tiers = risk_report['tier_distribution']\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(tiers.keys()), y=list(tiers.values()))\n",
    "plt.title('Risk Tier Distribution')\n",
    "plt.xlabel('Risk Tier')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.show()\n",
    "\n",
    "# Visualize weighted average interest rate and default probability\n",
    "metrics = risk_report['portfolio_metrics']\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(['Weighted Avg. Interest Rate', 'Weighted Avg. Default Prob.'],\n",
    "        [metrics['weighted_avg_interest_rate'], metrics['weighted_avg_default_probability']])\n",
    "plt.title('Portfolio Risk & Return')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
